global:
  exp_name: null
  exist_ok: false
  debug: False
  save_dir: runs
  pretrained: null
  resume: null
  cfg_transform: configs/tabular/transform.yaml
  device: cpu
trainer:
  name: MLTrainer
  args:
callbacks:
  - name: MLLoggerCallbacks
  - name: SKLearnCheckpointCallbacks
  - name: ShapValueExplainer
    args:
      plot_type: bar
  - name: LIMEExplainer
  - name: TensorboardCallbacks
metrics:
  - name: SKLAccuracy
  - name: SKLBalancedAccuracyMetric
  - name: SKLF1ScoreMetric
  - name: SKLPrecisionRecall
  - name: SKLEmbeddingProjection
model:
  name: GBClassifiers
  args:
      model_name: lightgbm
      model_config:
        n_estimators: 10 #The number of sequential trees to be modeled
        max_depth: 7 # The maximum depth of a tree.higher depth will allow model to learn relations very specific to a particular sample. Should be tuned
        learning_rate: 0.1 # impact of each tree on the final outcome
        reg_alpha: 0 #This will anyways be tuned later.
        reg_lambda: 1 #This will anyways be tuned later.
        early_stopping_rounds: 30
        objective: "multiclass"
data:
  dataset:
    train:
      name: TabularCSVDataset
      args:
        data_path: samples/titanic/train.csv
        target_column: Survived
        txt_classnames: samples/titanic/classnames.txt
    val:
      name: TabularCSVDataset
      args:
        data_path: samples/titanic/val.csv
        target_column: Survived
        txt_classnames: samples/titanic/classnames.txt
