{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:42.560942Z",
     "start_time": "2020-08-19T15:32:40.512917Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kay\n",
      "[nltk_data]     Kieran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.getter import *\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:42.568948Z",
     "start_time": "2020-08-19T15:32:42.563932Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    Resize((300,300)),\n",
    "    ToTensor(),\n",
    "    Normalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:42.584877Z",
     "start_time": "2020-08-19T15:32:42.571911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Dataset for Image Classification\n",
      "-------------------------------\n",
      "Number of samples: 2271\n",
      "Number of classes: 6\n",
      "\n",
      "Custom Dataset for Image Classification\n",
      "-------------------------------\n",
      "Number of samples: 256\n",
      "Number of classes: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"datasets/datasets/Garbage Classification\"\n",
    "voc_path = \"datasets/datasets/VOC/images\"\n",
    "voc_anno = \"datasets/datasets/VOC/annotations/pascal_train2012.json\"\n",
    "trainset = ImageClassificationDataset(data_path+ \"/train\", transforms= transforms, shuffle=True)\n",
    "valset = ImageClassificationDataset(data_path+ \"/val\", transforms= transforms, shuffle=True)\n",
    "\n",
    "print(trainset)\n",
    "print(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:42.609811Z",
     "start_time": "2020-08-19T15:32:42.587868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:42.615754Z",
     "start_time": "2020-08-19T15:32:42.611804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "BATCH_SIZE = 32\n",
    "trainloader = data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:42.622759Z",
     "start_time": "2020-08-19T15:32:42.616751Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "metrics = [AccuracyMetric(decimals=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:44.630716Z",
     "start_time": "2020-08-19T15:32:42.623732Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(trainset.classes)\n",
    "model = ResNet34(NUM_CLASSES,\n",
    "                 lr = 1e-4,\n",
    "                 criterion= criterion, \n",
    "                 optimizer= optimizer,\n",
    "                 metrics=  metrics,\n",
    "                 device = device)\n",
    "#load_checkpoint(model, \"weights/ResNet34-12.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:32:46.713378Z",
     "start_time": "2020-08-19T15:32:44.634706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1207523345947266\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    model.optimizer.zero_grad()\n",
    "    img = batch['img'].to(device)\n",
    "    label = batch['label'].to(device)\n",
    "    outputs = model(img)\n",
    "    loss = criterion(outputs, label)\n",
    "    print(loss.item())\n",
    "    #loss.backward()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T15:28:02.930252Z",
     "start_time": "2020-08-19T15:28:02.924295Z"
    }
   },
   "outputs": [],
   "source": [
    "cp = Checkpoint(save_per_epoch=6)\n",
    "trainer = Trainer(model,\n",
    "                 trainloader, \n",
    "                 valloader,\n",
    "                 checkpoint = cp, \n",
    "                 evaluate_per_epoch = 2)\n",
    "\n",
    "trainer.fit(num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitf1e933645d11461e8e62088c1ac0a078"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
