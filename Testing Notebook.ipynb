{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:08.293047Z",
     "start_time": "2020-08-21T17:42:06.008868Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.getter import *\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:08.297036Z",
     "start_time": "2020-08-21T17:42:08.294045Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    Resize((300,300)),\n",
    "    ToTensor(),\n",
    "    Normalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:08.516478Z",
     "start_time": "2020-08-21T17:42:08.298035Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_path = \"datasets/datasets/Garbage Classification\"\n",
    "voc_path = \"datasets/datasets/VOC/images\"\n",
    "voc_anno = {\n",
    "    \"train\": \"datasets/datasets/VOC/annotations/pascal_train2012.json\",\n",
    "    \"val\": \"datasets/datasets/VOC/annotations/pascal_val2012.json\"}\n",
    "\n",
    "#trainset = ImageClassificationDataset(data_path+ \"/train\", transforms= transforms, shuffle=True)\n",
    "#valset = ImageClassificationDataset(data_path+ \"/val\", transforms= transforms, shuffle = True)\n",
    "\n",
    "trainset = ObjectDetectionDataset(img_dir=voc_path, ann_path = voc_anno['train'],transforms= transforms)\n",
    "valset = ObjectDetectionDataset(img_dir=voc_path, ann_path = voc_anno['val'],transforms= transforms)\n",
    "NUM_CLASSES = len(trainset.classes)\n",
    "print(trainset)\n",
    "print(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:08.736370Z",
     "start_time": "2020-08-21T17:42:08.517461Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset.visualize_item(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:08.741864Z",
     "start_time": "2020-08-21T17:42:08.738364Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:08.748879Z",
     "start_time": "2020-08-21T17:42:08.742862Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.retinanet.retina_collator import *\n",
    "my_collator = trainset.collate_fn#RetinaNetCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:08.754830Z",
     "start_time": "2020-08-21T17:42:08.749874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "BATCH_SIZE = 4\n",
    "trainloader = data.DataLoader(trainset, batch_size=BATCH_SIZE, collate_fn = my_collator, shuffle=True)\n",
    "valloader = data.DataLoader(valset, batch_size=BATCH_SIZE,collate_fn = my_collator, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:42:45.001361Z",
     "start_time": "2020-08-21T17:42:42.992611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.detector import Detector\n",
    "\"\"\"from models.retinanet.loss import FocalLoss\n",
    "from models.retinanet.model import RetinaNet\n",
    "criterion = FocalLoss(num_classes = NUM_CLASSES, device = device)\n",
    "model = RetinaNet(num_classes = NUM_CLASSES).to(device)\"\"\"\n",
    "from models.ssd.model import SSD300, MultiBoxLoss\n",
    "model = SSD300(n_classes = NUM_CLASSES).to(device)\n",
    "criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T17:28:12.532229Z",
     "start_time": "2020-08-21T17:15:59.075381Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(trainloader):\n",
    "    optimizer.zero_grad()\n",
    "    imgs = batch['imgs'].to(device)\n",
    "    boxes = [x.to(device) for x in batch['boxes']]\n",
    "    labels = [x.to(device) for x in batch['labels']]\n",
    "    \n",
    "    \n",
    "    loc_preds, cls_preds = model(imgs)\n",
    "    loss = criterion(loc_preds,boxes, cls_preds,labels)\n",
    "  \n",
    "    #loss = sum([k for k in losses.values()])\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        print('[{}/{}] | Loss: {} '.format(idx, len(trainloader), loss.item()))\n",
    "        #print('[{}/{}] | C: {} | B: {} '.format(idx, len(trainloader), losses['C'].item(), losses['B'].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T13:06:06.741204Z",
     "start_time": "2020-08-21T13:06:06.572686Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        imgs = batch['imgs'].to(device)\n",
    "        boxes = [x.to(device) for x in batch['boxes']]\n",
    "        labels = [x.to(device) for x in batch['labels']]\n",
    "        loc_preds, cls_preds = model(imgs)\n",
    "        det_boxes, det_labels, det_scores = model.detect_objects(\n",
    "            loc_preds,\n",
    "            cls_preds,\n",
    "            min_score=0.01,\n",
    "            max_overlap=0.45,\n",
    "            top_k=200)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T13:06:57.171611Z",
     "start_time": "2020-08-21T13:06:57.160640Z"
    }
   },
   "outputs": [],
   "source": [
    "print(det_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T12:50:18.707041Z",
     "start_time": "2020-08-21T12:50:18.666152Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "metrics = [AccuracyMetric(decimals=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T12:57:40.398721Z",
     "start_time": "2020-08-20T12:57:35.902893Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(trainset.classes)\n",
    "model = ResNet34(NUM_CLASSES,\n",
    "                 lr = 1e-4,\n",
    "                 criterion= criterion, \n",
    "                 optimizer= optimizer,\n",
    "                 metrics=  metrics,\n",
    "                 device = device)\n",
    "#load_checkpoint(model, \"weights/ResNet34-12.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T12:57:41.732548Z",
     "start_time": "2020-08-20T12:57:41.315155Z"
    }
   },
   "outputs": [],
   "source": [
    "cp = Checkpoint(save_per_epoch=1)\n",
    "trainer = Trainer(model,\n",
    "                 trainloader, \n",
    "                 valloader,\n",
    "                 checkpoint = cp, \n",
    "                 evaluate_per_epoch = 1)\n",
    "\n",
    "trainer.fit(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T17:04:22.445151Z",
     "start_time": "2020-08-19T17:04:19.563219Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = trainer.inference_batch(valloader)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T17:04:35.298649Z",
     "start_time": "2020-08-19T17:04:35.078239Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 35\n",
    "print(valset.classes[preds[idx]])\n",
    "valset.visualize_item(idx, figsize = (8,8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitf1e933645d11461e8e62088c1ac0a078"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
